<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="PuzzleVQA: Diagnosing Multimodal Reasoning Skills of Language Models with Abstract Visual Patterns"
    />
    <meta
      name="keywords"
      content="PuzzleVQA,Multimodal,Language,Visual,Patterns"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>
      PuzzleVQA: Diagnosing Multimodal Reasoning Skills of Language Models with
      Abstract Visual Patterns
    </title>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.svg" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false"
        >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://chiayewken.com">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a class="navbar-item" href="https://reasoning-paths.github.io">
                Reasoning Paths Optimization
              </a>
              <a class="navbar-item" href="https://instruct-eval.github.io">
                InstructEval
              </a>
              <a
                class="navbar-item"
                href="https://github.com/declare-lab/HyperRED"
              >
                HyperRED
              </a>
              <a
                class="navbar-item"
                href="https://github.com/chiayewken/Span-ASTE"
              >
                Span-ASTE
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-2 publication-title">
                PuzzleVQA: Diagnosing Multimodal Reasoning Skills of Language
                Models with Abstract Visual Patterns
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://chiayewken.com">Yew Ken Chia</a
                  ><sup>1,2</sup>,</span
                >
                <span class="author-block">
                  <a href="https://openreview.net/profile?id=~Vernon_Toh1"
                    >Vernon Toh Yan Han</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="https://deepanwayx.github.io">Deepanway Ghosal</a
                  ><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://lidongbing.github.io">Lidong Bing</a
                  ><sup>2</sup>,
                </span>
                <span class="author-block">
                  <a href="https://soujanyaporia.github.io">Soujanya Poria</a
                  ><sup>1</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  ><sup>1</sup>Singapore University of Technology and
                  Design</span
                >
                <span class="author-block"
                  ><sup>2</sup>DAMO Academy, Alibaba Group
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Blog Link. -->
                  <span class="link-block">
                    <a
                      href="https://chiayewken.com/the-puzzling-failure-of-multimodal-ai-chatbots?showSharer=true"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon"> <i class="fa fa-book"></i> </span>
                      <span>Blog</span>
                    </a>
                  </span>
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a
                      href="https://aclanthology.org/2024.findings-acl.962/"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <!--                            <span class="link-block">-->
                  <!--                <a href="https://arxiv.org/abs/2011.12948"-->
                  <!--                   class="external-link button is-normal is-rounded is-dark">-->
                  <!--                  <span class="icon">-->
                  <!--                      <i class="ai ai-arxiv"></i>-->
                  <!--                  </span>-->
                  <!--                  <span>arXiv</span>-->
                  <!--                </a>-->
                  <!--              </span>-->
                  <!--                            &lt;!&ndash; Video Link. &ndash;&gt;-->
                  <!--                            <span class="link-block">-->
                  <!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
                  <!--                   class="external-link button is-normal is-rounded is-dark">-->
                  <!--                  <span class="icon">-->
                  <!--                      <i class="fab fa-youtube"></i>-->
                  <!--                  </span>-->
                  <!--                  <span>Video</span>-->
                  <!--                </a>-->
                  <!--              </span>-->

                  <!-- Code Link. -->
                  <span class="link-block">
                    <a
                      href="https://github.com/declare-lab/LLM-PuzzleTest/tree/master/PuzzleVQA"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Dataset Link. -->
                  <span class="link-block">
                    <a
                      href="https://huggingface.co/datasets/declare-lab/puzzlevqa"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon"> ðŸ¤— </span>
                      <span>Dataset</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video id="teaser" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/components.mp4" type="video/mp4" />
          </video>
          <h2 class="subtitle has-text-centered">
            PuzzleVQA is a challenging benchmark for multimodal reasoning over
            abstract patterns. The puzzle components include diverse layouts and
            objects, requiring perception and reasoning to solve.
          </h2>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Large multimodal models extend the impressive capabilities of
                large language models by integrating multimodal understanding
                abilities. However, it is not clear how they can emulate the
                general intelligence and reasoning ability of humans. As
                recognizing patterns and abstracting concepts are key to general
                intelligence, we introduce PuzzleVQA, a collection of puzzles
                based on abstract patterns. With this dataset, we evaluate large
                multimodal models with abstract patterns based on fundamental
                concepts, including colors, numbers, sizes, and shapes. Through
                our experiments on state-of-the-art large multimodal models, we
                find that they are not able to generalize well to simple
                abstract patterns. Notably, even GPT-4V cannot solve more than
                half of the puzzles.
              </p>
              <p>
                To diagnose the reasoning challenges in large multimodal models,
                we progressively guide the models with our ground truth
                reasoning explanations for visual perception, inductive
                reasoning, and deductive reasoning. Our systematic analysis
                finds that the main bottlenecks of GPT-4V are weaker visual
                perception and inductive reasoning abilities. Through this work,
                we hope to shed light on the limitations of large multimodal
                models and how they can better emulate human cognitive processes
                in the future.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <!--    <section class="hero is-light is-small">-->
    <!--      <div class="hero-body">-->
    <!--        <div class="container">-->
    <!--          <div id="results-carousel" class="carousel results-carousel">-->
    <!--            <div class="item item-1">-->
    <!--              <img src="./static/images/puzzle1.png" height="100%" />-->
    <!--            </div>-->
    <!--            <div class="item item-2">-->
    <!--              <img src="./static/images/puzzle2.png" height="100%" />-->
    <!--            </div>-->
    <!--            <div class="item item-3">-->
    <!--              <img src="./static/images/puzzle3.png" height="100%" />-->
    <!--            </div>-->
    <!--          </div>-->
    <!--        </div>-->
    <!--      </div>-->
    <!--    </section>-->

    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
          <div style="display: flex; justify-content: center">
            <h2 class="title" style="margin-bottom: 20px">Puzzle Samples</h2>
          </div>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-steve" style="height: 100%">
              <img src="./static/images/puzzle1.png" height="100%" />
            </div>
            <div class="item item-steve">
              <img src="./static/images/puzzle2.png" height="100%" />
            </div>
            <div class="item item-steve">
              <img src="./static/images/puzzle3.png" height="100%" />
            </div>
            <div class="item item-steve">
              <img src="./static/images/puzzle4.png" height="100%" />
            </div>
            <div class="item item-steve">
              <img src="./static/images/puzzle5.png" height="100%" />
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <div style="display: flex; justify-content: center">
            <h2 class="title" style="margin-top: 20px; margin-bottom: 20px">
              Results
            </h2>
          </div>
          <img
            id="results"
            src="./static/images/results.png"
            alt="RPO Results"
            width="100%"
          />
          <h2 class="subtitle has-text-centered">
            Our detailed analysis finds that the large gap between models like
            GPT-4V and human performance can be attributed to their weaker
            visual perception and inductive reasoning abilities.
          </h2>
        </div>
      </div>
    </section>

    <!--<section class="section">-->
    <!--    <div class="container is-max-desktop">-->
    <!--        &lt;!&ndash; Concurrent Work. &ndash;&gt;-->
    <!--        <div class="columns is-centered">-->
    <!--            <div class="column is-full-width">-->
    <!--                <h2 class="title is-3">Related Links</h2>-->

    <!--                <div class="content has-text-justified">-->
    <!--                    <p>-->
    <!--                        There's a lot of excellent work that was introduced around the same time as ours.-->
    <!--                    </p>-->
    <!--                    <p>-->
    <!--                        <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a>-->
    <!--                        introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.-->
    <!--                    </p>-->
    <!--                    <p>-->
    <!--                        <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a-->
    <!--                            href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>-->
    <!--                        both use deformation fields to model non-rigid scenes.-->
    <!--                    </p>-->
    <!--                    <p>-->
    <!--                        Some works model videos with a NeRF by directly modulating the density, such as <a-->
    <!--                            href="https://video-nerf.github.io/">Video-NeRF</a>, <a-->
    <!--                            href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a-->
    <!--                            href="https://neural-3d-video.github.io/">DyNeRF</a>-->
    <!--                    </p>-->
    <!--                    <p>-->
    <!--                        There are probably many more by the time you are reading this. Check out <a-->
    <!--                            href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>,-->
    <!--                        and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF-->
    <!--                        papers</a>.-->
    <!--                    </p>-->
    <!--                </div>-->
    <!--            </div>-->
    <!--        </div>-->
    <!--        &lt;!&ndash;/ Concurrent Work. &ndash;&gt;-->
    <!--    </div>-->
    <!--</section>-->

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{chia2024puzzlevqa,
  author    = {Yew Ken Chia and Vernon Toh Yan Han and Deepanway Ghosal and Lidong Bing and Soujanya Poria},
  title     = {PuzzleVQA: Diagnosing Multimodal Reasoning Skills of Language Models with Abstract Visual Patterns},
  journal   = {ACL},
  year      = {2024},
}</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <!--        <div class="content has-text-centered">-->
        <!--            <a class="icon-link"-->
        <!--               href="./static/videos/nerfies_paper.pdf">-->
        <!--                <i class="fas fa-file-pdf"></i>-->
        <!--            </a>-->
        <!--            <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
        <!--                <i class="fab fa-github"></i>-->
        <!--            </a>-->
        <!--        </div>-->
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >, based on
                <a href="https://github.com/nerfies/nerfies.github.io"
                  >Nerfies</a
                >.
              </p>
              <!--                    <p>-->
              <!--                        This means you are free to borrow the <a-->
              <!--                            href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
              <!--                        we just ask that you link back to this page in the footer.-->
              <!--                        Please remember to remove the analytics code included in the header of the website which-->
              <!--                        you do not want on your website.-->
              <!--                    </p>-->
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
